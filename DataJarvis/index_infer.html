<html>

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

  <title>
    AI4AI Team - EMO-Avatar Multimodal Emotional Support - Generated Results
  </title>
  <link href="./EchoMimic_Lifelike_Audio_Driven_Portrait_Animations_files/style.css" rel="stylesheet" />
  <style>
    @font-face {
      font-family: "monica-ext-font_YIBBBFG";
      src: url("chrome-extension://ofpnmcalabcbjgholdjcjblkibolbppb/static/fonts/Hind-Light.otf");
      font-weight: 300;
      font-display: swap;
    }

    @font-face {
      font-family: "monica-ext-font_YIBBBFG";
      src: url("chrome-extension://ofpnmcalabcbjgholdjcjblkibolbppb/static/fonts/Hind-Regular.otf");
      font-weight: 400;
      font-display: swap;
    }

    @font-face {
      font-family: "monica-ext-font_YIBBBFG";
      src: url("chrome-extension://ofpnmcalabcbjgholdjcjblkibolbppb/static/fonts/Hind-Medium.otf");
      font-weight: 500;
      font-display: swap;
    }

    @font-face {
      font-family: "monica-ext-font_YIBBBFG";
      src: url("chrome-extension://ofpnmcalabcbjgholdjcjblkibolbppb/static/fonts/Hind-SemiBold.otf");
      font-weight: 600;
      font-display: swap;
    }
  </style>
  <style id="monica-reading-highlight-style">
    .monica-reading-highlight {
      animation: fadeInOut 1.5s ease-in-out;
    }

    @keyframes fadeInOut {

      0%,
      100% {
        background-color: transparent;
      }

      30%,
      70% {
        background-color: rgba(2, 118, 255, 0.2);
      }
    }
  </style>
  <style>
    .video-responsive {
      position: relative;
      padding-bottom: 56.25%;
      /* 16:9 */
      height: 0;
      overflow: hidden;
      max-width: 100%;
      width: 100%;
    }

    .video-responsive iframe {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
    }

    .row {
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
      gap: 20px;
    }

    .video-responsive {
      flex: 1 1 45%;
      /* ÊØè‰∏™ËßÜÈ¢ëÊúÄÂ§öÂç†45%ÔºåËá™Âä®Êç¢Ë°å */
      min-width: 300px;
      /* ÊúÄÂ∞èÂÆΩÂ∫¶ÔºåÈò≤Ê≠¢Â§™Á™Ñ */
      max-width: 48%;
      box-sizing: border-box;
    }
  </style>
</head>

<body monica-locale="zh_CN" monica-version="5.5.1" monica-id="ofpnmcalabcbjgholdjcjblkibolbppb">
  <div class="content">
    <h1>
      <span></span><strong><br /><strong>EMO-Avatar</strong>: An LLM-Agent-Orchestrated Framework for Multimodal
        Emotional Support in Human Animation</strong>
    </h1>



    <div class="gallery" style="margin-bottom: 0">
      <div class="row" style="justify-content: center; text-align: center">
        <div class="video-responsive">
          <iframe src="https://www.youtube.com/embed/5nT0hZM8vLo" frameborder="0" allowfullscreen></iframe>
        </div>
      </div>
      <div class="row" style="justify-content: space-evenly; padding: 0; margin-bottom: 0">
        <figure style="width: 100%; margin: 25 0 0; text-align: center">
          <img src="./EchoMimic_Lifelike_Audio_Driven_Portrait_Animations_files/teaser.png"
            style="height: 400px; width: auto" />
        </figure>
      </div>
    </div>
  </div>
  <div class="content">
    <h2 style="text-align: center"><strong>Abstract</strong></h2>
    <p>
      Emotional Support Chatbots could unlock potential by providing scalable, low-cost, and personal emotional
      support, overcoming critical accessibility barriers inherent in traditional counseling. However, current
      text-based Chatbots fall short in conveying the multimodal empathy crucial in counseling. Humans naturally
      prefer face-to-face communication with peers to share feelings, encompassing spoken tone, micro-expressions, and
      body language to convey empathy. To bridge this gap, we propose EMO-Avatar, an LLM-agent-orchestrated framework
      that integrates emotional reasoning capabilities and multimodal expression in counseling. Our approach
      introduces two innovations: (1) a Multimodal Emotional Support Agent. EMO-Avatar can follow adaptive instruction
      across TTS, pose, micro-expressions, and body actions, leading to the generation of highly expressive human
      animations. (2) a Comforting-Exploration-Action support strategy; EMO-Avatar systematically integrates Hill's
      three-stage counseling theory into its emotional reasoning capability. Guided by the LLM's reasoning, this
      strategy informs response generation and displays stage-specific preferences for speech, body language, and
      expressions. EMO-Avatar can provide deeper emotional support and therapeutic human-like interactions.
      Experimental validation on the AvaMERG Challenge demonstrates EMO-Avatar's superior performance, achieving top-2
      ranking among 20 participants across response appropriateness, multimodal consistency, naturalness, and
      emotional expressiveness metrics <a href="https://avamerg.github.io/MM25-challenge/"></a>
    </p>
    <div id="teasers">
      <img src="./EchoMimic_Lifelike_Audio_Driven_Portrait_Animations_files/algo_framework.png" ,=""
        style="width: 100%" />
      <figcaption></figcaption>
    </div>
    <p id="authors" class="serif">
      <span style="font-size: 1.2em; font-weight: bold">Team AI4AI</span><br />

      <span style="font-size: 1em; margin-top: 0.8em">
        <a>EMO-Avatar - Multimodal Emotional Support Video -TOP2 Solution in ACMMMM25 Challenge</a>
      </span>
    </p>
    <div id="teasers">
      <img src="./author.png" ,="" style="width: 100%" />
      <figcaption></figcaption>
    </div>


    <font size="+2">

      <div style="
          text-align: center;
          display: flex;
          justify-content: space-between;
          margin: 10px 160px;
          font-size: 20;
        ">

        <a target="_blank" ,="" href="https://pan.baidu.com/s/1hmVOY2ISejRsaRfpiNbkUA?pwd=AI4A">
          <img src="./EchoMimic_Lifelike_Audio_Driven_Portrait_Animations_files/baidu.png" alt="Baidu Netdisk" ,=""
            style="width: 25px" />Baidu Netdisk</a>&nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank" ,="" href="https://avamerg.github.io/">
          <img src="./EchoMimic_Lifelike_Audio_Driven_Portrait_Animations_files/hugface.png" alt="homepage" ,=""
            style="width: 25px" />[Homepage] </a>&nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank" ,="" href="https://avamerg.github.io/MM25-challenge/">
          <img src="./EchoMimic_Lifelike_Audio_Driven_Portrait_Animations_files/modelscope.png" alt="challenge" ,=""
            style="width: 25px" />[ACMMM25 Challenge Link] </a>&nbsp;&nbsp;&nbsp;&nbsp;

      </div>
    </font>
  </div>
  <!-- ######################################################### -->
  <div class="content">
    <div id="teasers">
      <img src="./EchoMimic_Lifelike_Audio_Driven_Portrait_Animations_files/app1.png" ,="" style="width: 100%" />
      <figcaption></figcaption>
    </div>
    <h4 style="text-align: center">Comparison with Baseline Frames Generated by Other Models
      We sample the same audio clip (22 seconds) to drive all baseline models and randomly sample frames at 3-second
      intervals. The result generated by EchoMimic exhibits noticeable distortion, which we attribute to its lack of
      training data for half-body human driving. Our method demonstrates superior generation quality and stability,
      particularly in long-duration, high-resolution video synthesis.</h4>
  </div>

  <div class="content">
    <p>
      <strong>You can access more of our videos through Baidu Netdisk.</strong>
      Shared via Baidu Netdisk with Online Videos:
      audio video json README ‚Äî 4 files
      üîó Link: <a
        href="https://pan.baidu.com/s/1hmVOY2ISejRsaRfpiNbkUA?pwd=AI4A">https://pan.baidu.com/s/1hmVOY2ISejRsaRfpiNbkUA?pwd=AI4A</a>
      üîë Access code: AI4A
    </p>
  </div>
  <div class="content">
    <p>
      <strong> Network quality may affect video playback results. Please check the youtube connection.</strong>
      PS: Youtube Login is required.
    </p>
  </div>

  <!-- <h3></h3> -->

  <div class="content">
    <h2 style="text-align: center"><strong>Gallery (Youtube Videos)</strong></h2>


    <h3>Dialogue between two people</h3>
    <div class="gallery">
      <div class="row" style="margin-bottom: 20px">
        <div class="video-responsive">
          <iframe src="https://www.youtube.com/embed/5XnBMh4EcCQ" frameborder="0" allowfullscreen></iframe>
        </div>
        <div class="video-responsive">
          <iframe src="https://www.youtube.com/embed/hFkW-loEIiI" frameborder="0" allowfullscreen></iframe>
        </div>
      </div>
    </div>

    <h3>Short conversations</h3>
    <div class="gallery">
      <div class="row" style="margin-bottom: 20px">
        <div class="video-responsive">
          <iframe src="https://www.youtube.com/embed/cfH1adPeZYA" frameborder="0" allowfullscreen></iframe>
        </div>
        <!-- https://youtu.be/cfH1adPeZYA -->
        <!-- https://youtu.be/84RFmX8XyL8 -->
        <div class="video-responsive">
          <iframe src="https://www.youtube.com/embed/84RFmX8XyL8" frameborder="0" allowfullscreen></iframe>
        </div>
      </div>
    </div>

    <h3>Counseling conversations with paralanguage</h3>
    <div class="gallery">
      <div class="row" style="margin-bottom: 20px">
        <div class="video-responsive">
          <iframe src="https://www.youtube.com/embed/qmOcgVzWunA" frameborder="0" allowfullscreen></iframe>
        </div>
        <!-- https://youtu.be/qmOcgVzWunA -->
        <div class="video-responsive">
          <iframe src="https://www.youtube.com/embed/dZKp_7m0z7Y" frameborder="0" allowfullscreen></iframe>
        </div>
        <!-- https://youtu.be/dZKp_7m0z7Y -->
      </div>
    </div>

    <h3>Long videos</h3>
    <div class="gallery">
      <div class="row">
        <div class="video-responsive">
          <iframe src="https://www.youtube.com/embed/6fhEbouIPlc" frameborder="0" allowfullscreen></iframe>
        </div>
        <!-- https://youtu.be/6fhEbouIPlc -->
        <div class="video-responsive">
          <iframe src="https://www.youtube.com/embed/W3dbJitPuN4" frameborder="0" allowfullscreen></iframe>
        </div>
        <!-- https://youtu.be/W3dbJitPuN4 -->
      </div>
    </div>
  </div>
  <!-- <div class="video-responsive">
    <iframe src="https://www.youtube.com/embed/cfH1adPeZYA" frameborder="0" allowfullscreen></iframe> -->
  </div>
  <!-- ######################################################### -->
  <div class="content">
    <div id="teasers">
      <img src="./EchoMimic_Lifelike_Audio_Driven_Portrait_Animations_files/app2.png" ,="" style="width: 100%" />
      <figcaption></figcaption>
    </div>
    <h4 style="text-align: center">An example of EMO-Avatar's input and output in AvaMERG Challenge. In this case,
      EMO-Avatar generated the fourth-round emotional support animation based on conversation history (videos) from the
      previous three rounds. Comforting and exploration strategies are adopted in this case.</h4>
  </div>
  <!-- Awards Section -->
  <div class="content">

    <div class="awards-section" style="text-align: center; margin: 30px 0;">
      <h2 style="margin-bottom: 20px; font-size: 2.2em;">üèÜ Awards üèÜ</h2>

      <div class="award-content" style="display: flex; justify-content: space-between; gap: 20px; width: 100%;">
        <div class="award-item" style="text-align: center; flex: 1;">
          <img src="./AI4AI_2.jpg" alt="Bronze Medal" style="width: 100%; height: auto; margin-bottom: 10px;" />
          <h3>ü•â Subtask 1 - 3rd Place</h3>
          <h4> Multimodal-Aware Empathetic Response Generation.</h4>
        </div>

        <div class="award-item" style="text-align: center; flex: 1;">
          <img src="./AI4AI_1.jpg" alt="Silver Medal" style="width: 100%; height: auto; margin-bottom: 10px;" />
          <h3>ü•à Subtask 2 - 2nd Place</h3>
          <h4> Multimodal Empathetic Response Generation. </h4>
        </div>
      </div>
    </div>

    <p style="margin-top: 20px; font-size: 1.1em; color: #666;">
      AvaMERG@MM2025 Grand Challenge - Avatar-based Multimodal Empathetic Response Generation
      https://avamerg.github.io/MM25-challenge/
    </p>
</body>

</html>